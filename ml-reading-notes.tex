\documentclass[a4paper, 12pt]{article}

\usepackage{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{fullpage}
\usepackage{url}
\usepackage{graphicx}
\usepackage{inputenc}
\usepackage{titling}
\usepackage{hyperref}
\usepackage{txfonts}
\usepackage{bbold}

\date{\today}
\title{Machine Learning Reading Notes} 

\author{Brendan Duke}

\begin{document}

\maketitle

\section{Definitions}

\textbf{Deep Neural Networks (DNNs)} are engineered systems inspired by the
biological brain\cite{Goodfellow-et-al-2016-Book}.

The \textbf{softmax function} is a continuous differentiable version of the
argmax function, where the result is represented as a one-hot
vector\cite[Chapter~6]{Goodfellow-et-al-2016-Book}. Softmax is a way of
representing probability distributions over a discrete variable that can take
on $n$ possible values.

Formally, softmax is given by Equation~\ref{softmax_eqn}.

\begin{equation}
        \textrm{softmax}(\boldsymbol{z})_i = \frac{e^{z_i}}{\sum_je^{z_j}}
        \label{softmax_eqn}
\end{equation}

\textbf{Mahalanobis Distance}

\textbf{Neighbourhood Components Analysis (NCA)} is a method of learning a
Mahalanobis distance metric, and can also be used in linear dimensionality
reduction\cite{NIPS2004_2566}.

The \textbf{PCKh} metric, used by the MPII Human Pose Dataset, defines a joint
estimate as matching the ground truth if the estimate lies within 50\% of the
head segment length\cite{andriluka-2d-2014-853}. The head segment length is
defined as the diagonal across the annotated head rectangle in the MPII data,
multiplied by a factor of 0.6. Details can be found by examining the MATLAB
\href{http://human-pose.mpi-inf.mpg.de/results/mpii_human_pose/evalMPII.zip}{evaluation script}
provided with the MPII dataset.

\phantomsection
\label{nonmax_supression}
\textbf{Non-maximum suppression} in object detection, in general, is a set of
methods used to prune an initial set of object bounding boxes that may be
uncorrelated with the actual object detections in an image, down to a subset
that are\cite{DBLP:conf/accv/RotheGG14}. In edge detection, non-maximum
suppression is used to suppress any pixels (i.e. not include them in the set of
detected edges) that are not the maximum response in their neighbourhood.

\phantomsection
\label{LSTM}
% TODO(brendan): Diagrams and equations for LSTM. Definition for RNNs. Should
% be a distillation of Chapter 10 of Goodfellow book.
\textbf{LSTM} (Long Short Term
Memory) neural networks are a type of recurrent neural network whose
characteristic feature is the presence of a gated self-loop that allows
retention of its ``cell state'', which are the pre-non-linearity activations of
the previous time step\cite[Chapter~10]{Goodfellow-et-al-2016-Book}.

Cell state is updated at each time step according to
Equation~\ref{lstm_cell_state_update}.

\begin{equation}
        s_i^{(t)} = f_i^{(t)} s_i^{(t - 1)} + g_i^{(t)}
                \sigma \left( b_i + \sum_j U_{i, j} x_j^{(t)} + \sum_j W_{i, j} h_j^{(t - 1)}\right)
        \label{lstm_cell_state_update}
\end{equation}

The vectors $\boldsymbol{f^{(t)}}$ and $\boldsymbol{g^{(t)}}$ in
Equation~\ref{lstm_cell_state_update} also take inputs from $\boldsymbol{x^{(t)}}$
and $\boldsymbol{h^{(t - 1)}}$, with their own weight tensors and bias vectors
$\boldsymbol{U}^f$, $\boldsymbol{W}^f$ and $\boldsymbol{b}^f$, $\boldsymbol{U}^g$,
$\boldsymbol{W}^g$ and $\boldsymbol{b}^f$, respectively.

Similar gate functions exist to gate the inputs and outputs to the LSTM, as
well.

\section{Paper Summaries}
 
\subsection{DeepPose: Human Pose Estimation via Deep Neural
            Networks\cite{DBLP:journals/corr/ToshevS13}}

This paper uses DNNs as a method for human pose estimation, based on the
success of \cite{NIPS2013_5207} and \cite{DBLP:journals/corr/GirshickDDM13} for
object detection using DNNs.

This is in contrast to the existing work in human pose estimation at the time,
which focused on explicitly designed pose models. Papers about these methods
can be found in the ``Related Work'' section of
\cite{DBLP:journals/corr/ToshevS13}.

The input to the 7-layered convolutional DNN (based on
AlexNet\cite{NIPS2012_4824}) is the full image.

\subsection{Dropout: A Simple Way to Prevent Neural Networks from
            Overfitting\cite{Srivastava:2014:DSW:2627435.2670313}}

\textbf{Dropout} is a technique used to overcome the problem of overfitting in
deep neural nets with large numbers of parameters. The idea is to train using
many ``thinned'' networks, chosen by randomly removing subsets of units and
their connections. The predictions from the thinned networks are approximately
averaged at test time by using a single, unthinned, network with reduced
weights.

\begin{itemize}
        \item Existing regularization methods: stopping training as soon as
                validation error stops improving, L1 and L2 regularization, and
                weight sharing\cite{Nowlan:1992:SNN:148167.148169}.
\end{itemize}

\subsection{End-to-end people detection in crowded
            scenes\cite{DBLP:journals/corr/StewartA15}}

This paper is focused on jointly creating a set of bounding-box predictions for
people in crowded scenes using GoogLeNet and a
\hyperref[LSTM]{recurrent LSTM layer} as a controller. Since bounding-box
predictions are generated jointly, common post-processing steps such as
\hyperref[nonmax_supression]{non-maximum suppression} are unnecessary.  All
components of the system are trained end-to-end using back propagation.

The end-to-end people detection method is contrasted with the object detection
methods of R-CNN in \cite{DBLP:journals/corr/GirshickDDM13} and OverFeat in
\cite{DBLP:journals/corr/SermanetEZMFL13}.
\cite{DBLP:journals/corr/GirshickDDM13} and
\cite{DBLP:journals/corr/SermanetEZMFL13} rely on non-maximum suppression,
which does not use access to image information to infer bounding box positions
since non-maximum suppression acts only on bounding boxes. Also, in end-to-end
people detection, the decoding stage is learned using LSTMs, instead of using
specialized methods as in \cite{VisualPhrases} and \cite{TaAnSc_14:occluded}.

Early related work can be found in \cite{Felzenszwalb:2010:ODD:1850486.1850574}
and \cite{Leibe:2005:PDC:1068507.1069006}. Best performing object detectors at
the time were \cite{DBLP:journals/corr/GirshickDDM13},
\cite{DBLP:journals/corr/SermanetEZMFL13}, \cite{Uijlings13},
\cite{DBLP:journals/corr/ZhangBS15} and \cite{DBLP:journals/corr/SzegedyREA14}.

Sequence modeling is done using LSTMs as in
\cite{DBLP:journals/corr/SutskeverVL14} (used for machine translation) and
\cite{DBLP:journals/corr/KarpathyF14} (used for image captioning). The loss
function is similar to the loss function proposed in
\cite{Graves06connectionisttemporal} in that the loss function encourages the
model to make predictions in descending order of confidence.

A new training set collected from public webcams, called ``Brainwash'', is
produced. Brainwash consists of 11917 images with 91146 labelled people. 1000
images are allocated for testing and validation, hence training, test and
validation sets contain 82906, 4922 and 3318 labels, respectively.

A pre-trained GoogLeNet\cite{going-deeper-szegedy43022} is used to produce
encoded features as input to the LSTM. The GoogLeNet features are further
fine-tuned by the training process.  Using GoogLeNet, a feature vector of
length 1024 is produced for each region over a 15x20 grid of regions that
covers the entire 480x640 input image. Each cell in the grid has a receptive
field of 139x139, and is trained to produce a set (with fixed cardinality five)
of distinct bounding boxes in the center 64x64 region.

At each step, the LSTM for each grid cell, of which there are 300 in total,
produces a new bounding box and corresponding confidence that the bounding box
contains a person $\boldsymbol{b} = \{\boldsymbol{b}_{pos}, b_c\}$, where
$\boldsymbol{b}_{pos} = (b_x, b_y, b_w, b_h) \in \varmathbb{R}^4$ and
$b_c \in [0, 1]$. The prediction algorithm stops when the confidence drops
below a set threshold. The LSTM units have 250 memory states, no bias units,
and no output non-linearities. Each LSTM unit adds its output to the image
representation, and feeds the result into the next LSTM unit. Comparable
results are found by only presenting the image representation as input to the
first LSTM unit.

A new loss function that operates on sets of bounding-box predictions is
introduced. Denoting bounding boxes generated by the model as
$C = \{\tilde{\boldsymbol{b}}_i\}$, and ground truth bounding boxes by
$G = \{\boldsymbol{b}_i\}$, the loss function is given by
Equation~\ref{loss-eqn}.

\begin{equation}
        L(G, C, f) = \alpha\sum_i^{|G|}
                             l_{pos}\left(\tilde{\boldsymbol{b}}_{pos}^i, \boldsymbol{b}_{pos}^{f(i)}\right) +
                     \sum_j^{|C|} l_c\left(\tilde{b}_c^j, y_j\right)
        \label{loss-eqn}
\end{equation}

In Equation~\ref{loss-eqn}, $f(i)$ is an injective function $G \rightarrow C$
that assigns one ground truth to each index $i$ up to the number of ground
truths, $l_{pos}$ is the $L_1$ displacement between bounding boxes, and $l_c$
is a cross-entropy loss on a candidate's confidence that a bounding box exists,
where $y_j = \mathbb{1}\{f^{-1}(j) \neq \varnothing\}$. $\alpha$ is set to 0.03
from cross-validation.

In creating $f(i)$ in Equation~\ref{loss-eqn} to assign candidate predictions
to ground truths, the
$G \times C \rightarrow \varmathbb{R} \times \varmathbb{N} \times \varmathbb{N}$
function
$\Delta\left(\boldsymbol{b}^i, \tilde{\boldsymbol{b}}^j\right) = (o_{ij}, r_i, d_{ij})$
is used to lexicographically order pairs first by $o$, then $r$, then $d$,
where $o$ is one if there is sufficient overlap between candidate and ground
truth and zero otherwise, $r$ is the prediction's confidence, and $d$ is the
$L_1$ displacement between candidate and ground truth bounding boxes.

With an AP (average precision) of 0.78 and EER (equal error rate) of 0.81, the
$f(i)$ produced by minimizing $\Delta$, using the
\href{https://en.wikipedia.org/wiki/Hungarian_algorithm}{Hungarian algorithm},
is found to improve on AP and EER compared with a fixed assignment of $f(i)$,
or selecting the first $k$ highest ranked ($L_\textrm{firstk}$). COUNT
(Absolute difference between number of predicted and ground truth detections)
for $f(i)$ with Hungarian was 0.76 compared with 0.74 for $L_\textrm{firstk}$.
As a baseline, Overfeat-GoogLeNet (bounding-box regression on each cell,
followed by non-maximum suppression, as in
\cite{DBLP:journals/corr/SermanetEZMFL13}) achieved 0.67, 0.71 and 1.05 AP, EER
and COUNT, respectively.

The system is trained with learning rate 0.2, decreased by a factor of 0.8
every 100 000 iterations (with convergence occurring after 500 000 iterations),
and momentum 0.5. Gradient clipping is done at 2-norm of 0.1.

Training without finetuning GoogLeNet reduces AP by 0.29.

GoogLeNet activations are scaled down by a factor of 100 before being input to
the decoder, since decoder weights are initialized according to a uniform
distribution in $[-0.1, 0.1]$, while GoogLeNet activations are in $[-80, 80]$.
Regression predictions from GoogLeNet are scaled up by 100 before comparing
with ground truth locations (which are in $[-64, 64]$).

Dropout with probability 0.15 is used on the output of each LSTM, removal of
which decreases AP by 0.011. Images are jittered by up to 32 pixels in
horizontal and vertical directions, and scaled by a factor between 0.9 and 1.1.
$L_2$ regularization of weights in the network was removed entirely. When using
the original $2^{-4}$ $L_2$ regularization multiplier on GoogLeNet only, the
network was unable to train. An $L_2$ regularization multiplier on GoogLeNet of
$10^{-6}$ reduced AP by 0.03.

It is found that AP (on the validation set) increases from 0.82 to 0.85 when
using separate weights connecting each of the LSTM outputs to predicted
candidates.

At test time, per-region predictions are merged by adding a new region at each
iteration, and destroying any new bounding boxes that overlap previously
accepted bounding boxes, under the constraint that any given bounding box can
destroy at most one other bounding box. An ordering function
$\Delta': A \times C \rightarrow \varmathbb{N} \times \varmathbb{R}$ given by
$\Delta'(\boldsymbol{b}_i, \tilde{\boldsymbol{b}}_j) = (m_{ij}, d_{ij})$ where
$m_{ij}$ denotes intersection of boxes and $d_{ij}$ is $L_1$ displacement, is
minimized using the Hungarian algorithm in order to find a bipartite matching.
At each step, any new candidate that is not intersecting in the matching is
added to the set of accepted candidates.

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,ml-reading-notes}

\end{document}
