@article{Srivastava:2014:DSW:2627435.2670313,
        author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
        title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
        journal = {J. Mach. Learn. Res.},
        issue_date = {January 2014},
        volume = {15},
        number = {1},
        month = jan,
        year = {2014},
        issn = {1532-4435},
        pages = {1929--1958},
        numpages = {30},
        url = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
        acmid = {2670313},
        publisher = {JMLR.org},
        keywords = {deep learning, model combination, neural networks, regularization},
}

@article{Nowlan:1992:SNN:148167.148169,
        author = {Nowlan, Steven J. and Hinton, Geoffrey E.},
        title = {Simplifying Neural Networks by Soft Weight-sharing},
        journal = {Neural Comput.},
        issue_date = {July 1992},
        volume = {4},
        number = {4},
        month = jul,
        year = {1992},
        issn = {0899-7667},
        pages = {473--493},
        numpages = {21},
        url = {http://dx.doi.org/10.1162/neco.1992.4.4.473},
        doi = {10.1162/neco.1992.4.4.473},
        acmid = {148169},
        publisher = {MIT Press},
        address = {Cambridge, MA, USA},
}

@article{DBLP:journals/corr/ToshevS13,
  author    = {Alexander Toshev and Christian Szegedy},
  title     = {DeepPose: Human Pose Estimation via Deep Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1312.4659},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.4659},
  timestamp = {Mon, 06 Jan 2014 15:10:41 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ToshevS13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@unpublished{Goodfellow-et-al-2016-Book,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    note={Book in preparation for MIT Press},
    url={http://www.deeplearningbook.org},
    year={2016}
}

@incollection{NIPS2013_5207,
        title = {Deep Neural Networks for Object Detection},
        author = {Szegedy, Christian and Toshev, Alexander and Erhan, Dumitru},
        booktitle = {Advances in Neural Information Processing Systems 26},
        editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
        pages = {2553--2561},
        year = {2013},
        publisher = {Curran Associates, Inc.},
        url = {http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf}
}

@article{DBLP:journals/corr/GirshickDDM13,
  author    = {Ross B. Girshick and
               Jeff Donahue and
               Trevor Darrell and
               Jitendra Malik},
  title     = {Rich feature hierarchies for accurate object detection and semantic
               segmentation},
  journal   = {CoRR},
  volume    = {abs/1311.2524},
  year      = {2013},
  url       = {http://arxiv.org/abs/1311.2524},
  timestamp = {Tue, 03 Dec 2013 15:04:21 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GirshickDDM13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{NIPS2012_4824,
        title = {ImageNet Classification with Deep Convolutional Neural Networks},
        author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
        booktitle = {Advances in Neural Information Processing Systems 25},
        editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
        pages = {1097--1105},
        year = {2012},
        publisher = {Curran Associates, Inc.},
        url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}

@incollection{NIPS2010_4143,
        title = {Pose-Sensitive Embedding by Nonlinear NCA Regression},
        author = {Graham W. Taylor and Fergus, Rob and George Williams and Ian Spiro and Bregler, Christoph},
        booktitle = {Advances in Neural Information Processing Systems 23},
        editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
        pages = {2280--2288},
        year = {2010},
        publisher = {Curran Associates, Inc.},
        url = {http://papers.nips.cc/paper/4143-pose-sensitive-embedding-by-nonlinear-nca-regression.pdf}
}

@incollection{NIPS2004_2566,
        title = {Neighbourhood Components Analysis},
        author = {Jacob Goldberger and Hinton, Geoffrey E and Sam T. Roweis and Salakhutdinov, Ruslan R},
        booktitle = {Advances in Neural Information Processing Systems 17},
        editor = {L. K. Saul and Y. Weiss and L. Bottou},
        pages = {513--520},
        year = {2005},
        publisher = {MIT Press},
        url = {http://papers.nips.cc/paper/2566-neighbourhood-components-analysis.pdf}
}

@inproceedings {andriluka-2d-2014-853,
        title = {2D Human Pose Estimation: New Benchmark and State of the Art Analysis},
        booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year = {2014},
        month = {June},
        attachments = {https://www.d2.mpi-inf.mpg.de/sites/default/files/andriluka14cvpr.pdf , https://www.d2.mpi-inf.mpg.de/sites/default/files/supplementary_material.pdf},
        author = {Mykhaylo Andriluka and Leonid Pishchulin and Peter Gehler and Schiele, Bernt}
}

@article{DBLP:journals/corr/StewartA15,
        author    = {Russell Stewart and Mykhaylo Andriluka},
        title     = {End-to-end people detection in crowded scenes},
        journal   = {CoRR},
        volume    = {abs/1506.04878},
        year      = {2015},
        url       = {http://arxiv.org/abs/1506.04878},
        timestamp = {Wed, 01 Jul 2015 15:10:24 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/StewartA15},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/accv/RotheGG14,
        author    = {Rasmus Rothe and Matthieu Guillaumin and Luc J. Van Gool},
        title     = {Non-maximum Suppression for Object Detection by Passing Messages Between Windows},
        booktitle = {Computer Vision - {ACCV} 2014 - 12th Asian Conference on Computer Vision, Singapore, Singapore, November 1-5, 2014, Revised Selected Papers, Part {I}},
        pages     = {290--306},
        year      = {2014},
        url       = {http://dx.doi.org/10.1007/978-3-319-16865-4_19},
        doi       = {10.1007/978-3-319-16865-4_19},
        timestamp = {Mon, 05 Sep 2016 10:00:01 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/conf/accv/RotheGG14},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{going-deeper-szegedy43022,
        title = {Going Deeper with Convolutions},
        author  = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre
                   Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan
                   and Vincent Vanhoucke and Andrew Rabinovich},
        abstract = {We propose a deep convolutional neural network architecture
                    codenamed "Inception", which was responsible for setting the
                    new state of the art for classification and detection
                    in the ImageNet Large-Scale Visual Recognition
                    Challenge 2014 (ILSVRC 2014). The main hallmark of this
                    architecture is the improved utilization of the
                    computing resources inside the network. This was
                    achieved by a carefully crafted design that allows for
                    increasing the depth and width of the network while
                    keeping the computational budget constant. To optimize
                    quality, the architectural decisions were based on the
                    Hebbian principle and the intuition of multi-scale
                    processing. One particular incarnation used in our
                    submission for ILSVRC 2014 is called GoogLeNet, a 22
                    layers deep network, the quality of which is assessed
                    in the context of classification and detection.},
        comments = {Suggest as future work to automate use of the principles
                    used to design GoogLeNet to find architectures for other
                    applications.},
        year  = 2015,
        URL = {http://arxiv.org/abs/1409.4842},
        booktitle = {Computer Vision and Pattern Recognition (CVPR)}
}

@article{DBLP:journals/corr/SermanetEZMFL13,
        author    = {Pierre Sermanet and
                David Eigen and
                        Xiang Zhang and
                        Micha{\"{e}}l Mathieu and
                        Rob Fergus and
                        Yann LeCun},
        title     = {OverFeat: Integrated Recognition, Localization and Detection using
                Convolutional Networks},
        journal   = {CoRR},
        volume    = {abs/1312.6229},
        year      = {2013},
        url       = {http://arxiv.org/abs/1312.6229},
        timestamp = {Mon, 06 Jan 2014 15:10:41 +0100},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SermanetEZMFL13},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{VisualPhrases,
        author = {Sadeghi, Mohammad Amin and Farhadi, Ali},
        title = {Recognition using Visual Phrases},
        conferense = {Computer Vision and Pattern Recognition (CVPR)},
        year = {2011},
}

@article{TaAnSc_14:occluded,
        title = {Detection and Tracking of Occluded People},
        author = {Siyu Tang nd Mykhaylo Andriluka nd Bernt Schiele},
        year = {2014},
        date = {2014-01-01},
        journal = {International Journal of Computer Vision (IJCV)},
        volume = {110},
        number = {1},
        pages = {58--69},
        publisher = {Springer}
}

@article{Felzenszwalb:2010:ODD:1850486.1850574,
        author = {Felzenszwalb, Pedro F. and Girshick, Ross B. and McAllester, David and Ramanan, Deva},
        title = {Object Detection with Discriminatively Trained Part-Based Models},
        journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
        issue_date = {September 2010},
        volume = {32},
        number = {9},
        month = sep,
        year = {2010},
        issn = {0162-8828},
        pages = {1627--1645},
        numpages = {19},
        url = {http://dx.doi.org/10.1109/TPAMI.2009.167},
        doi = {10.1109/TPAMI.2009.167},
        acmid = {1850574},
        publisher = {IEEE Computer Society},
        address = {Washington, DC, USA},
        keywords = {Object recognition, Object recognition, deformable models, pictorial structures, discriminative training, latent SVM., deformable models, discriminative training, latent SVM., pictorial structures},
}

@inproceedings{Leibe:2005:PDC:1068507.1069006,
        author = {Leibe, Bastian and Seemann, Edgar and Schiele, Bernt},
        title = {Pedestrian Detection in Crowded Scenes},
        booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1 - Volume 01},
        series = {CVPR '05},
        year = {2005},
        isbn = {0-7695-2372-2},
        pages = {878--885},
        numpages = {8},
        url = {http://dx.doi.org/10.1109/CVPR.2005.272},
        doi = {10.1109/CVPR.2005.272},
        acmid = {1069006},
        publisher = {IEEE Computer Society},
        address = {Washington, DC, USA},
}

@ARTICLE{Uijlings13,
        author = {J.R.R. Uijlings and K.E.A. van de Sande and T. Gevers and A.W.M.
                Smeulders},
        title = {Selective Search for Object Recognition},
        journal = {International Journal of Computer Vision},
        year = {2013},
        doi = {10.1007/s11263-013-0620-5},
        owner = {jrruijli},
        timestamp = {2013.02.06},
        url = {http://www.huppelen.nl/publications/selectiveSearchDraft.pdf}
}

@article{DBLP:journals/corr/ZhangBS15,
        author    = {Shanshan Zhang and Rodrigo Benenson and Bernt Schiele},
        title     = {Filtered Channel Features for Pedestrian Detection},
        journal   = {CoRR},
        volume    = {abs/1501.05759},
        year      = {2015},
        url       = {http://arxiv.org/abs/1501.05759},
        timestamp = {Mon, 02 Feb 2015 14:12:25 +0100},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/ZhangBS15},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/SzegedyREA14,
        author    = {Christian Szegedy and Scott E. Reed and Dumitru Erhan and Dragomir Anguelov},
        title     = {Scalable, High-Quality Object Detection},
        journal   = {CoRR},
        volume    = {abs/1412.1441},
        year      = {2014},
        url       = {http://arxiv.org/abs/1412.1441},
        timestamp = {Fri, 08 Apr 2016 07:34:30 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SzegedyREA14},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/KarpathyF14,
        author    = {Andrej Karpathy and Fei{-}Fei Li},
        title     = {Deep Visual-Semantic Alignments for Generating Image Descriptions},
        journal   = {CoRR},
        volume    = {abs/1412.2306},
        year      = {2014},
        url       = {http://arxiv.org/abs/1412.2306},
        timestamp = {Mon, 01 Jun 2015 08:26:33 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/KarpathyF14},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/SutskeverVL14,
        author    = {Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
        title     = {Sequence to Sequence Learning with Neural Networks},
        journal   = {CoRR},
        volume    = {abs/1409.3215},
        year      = {2014},
        url       = {http://arxiv.org/abs/1409.3215},
        timestamp = {Wed, 01 Oct 2014 15:00:04 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SutskeverVL14},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@INPROCEEDINGS{Graves06connectionisttemporal,
        author = {Alex Graves and Santiago Fernández and Faustino Gomez},
        title = {Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks},
        abstract = {Many real-world sequence learning tasks require the
                    prediction of sequences of labels from noisy, unsegmented input
                    data. In speech recognition, for example, an acoustic
                    signal is transcribed into words or sub-word units.
                    Recurrent neural networks (RNNs) are powerful sequence
                    learners that would seem well suited to such tasks.
                    However, because they require pre-segmented training
                    data, and post-processing to transform their outputs
                    into label sequences, their applicability has so far
                    been limited. This paper presents a novel method for
                    training RNNs to label unsegmented sequences directly,
                    thereby solving both problems. An experiment on the TIMIT
                    speech corpus demonstrates its advantages over both a
                    baseline HMM and a hybrid HMM-RNN. 1.},
        booktitle = {In Proceedings of the International Conference on Machine Learning, ICML 2006},
        year = {2006},
        pages = {369--376}
}

@article{Hochreiter:1997:LSM:1246443.1246450,
        author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
        title = {Long Short-Term Memory},
        journal = {Neural Comput.},
        issue_date = {November 15, 1997},
        volume = {9},
        number = {8},
        month = nov,
        year = {1997},
        issn = {0899-7667},
        pages = {1735--1780},
        numpages = {46},
        url = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
        doi = {10.1162/neco.1997.9.8.1735},
        acmid = {1246450},
        publisher = {MIT Press},
        address = {Cambridge, MA, USA},
        abstract = {
                Learning to store information over extended time intervals by
                recurrent backpropagation takes a very long time,
                mostly because of insufficient, decaying error backflow. We
                briefly review Hochreiter's (1991) analysis of this
                problem, then address it by introducing a novel,
                efficient, gradient based method called long short-term memory
                (LSTM).  Truncating the gradient where this does not do
                harm, LSTM can learn to bridge minimal time lags in
                excess of 1000 discrete-time steps by enforcing
                constant error flow through constant error carousels
                within special units.  Multiplicative gate units learn
                to open and close access to the constant error flow.
                LSTM is local in space and time; its computational
                complexity per time step and weight is O. 1. Our
                experiments with artificial data involve local,
                distributed, real-valued, and noisy pattern representations. In
                comparisons with real-time recurrent learning, back
                propagation through time, recurrent cascade
                correlation, Elman nets, and neural sequence chunking,
                LSTM leads to many more successful runs, and learns much
                faster. LSTM also solves complex, artificial
                long-time-lag tasks that have never been solved by
                previous recurrent network algorithms.
        }
}

@article{DBLP:journals/corr/HeZRS15,
        author    = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian
                     Sun},
        title     = {Deep Residual Learning for Image Recognition},
        journal   = {CoRR},
        volume    = {abs/1512.03385},
        year      = {2015},
        url       = {http://arxiv.org/abs/1512.03385},
        timestamp = {Wed, 30 Mar 2016 23:40:00 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HeZRS15},
        bibsource = {dblp computer science bibliography, http://dblp.org},
        abstract = {
                Deeper neural networks are more difficult to train. We present a residual
                learning framework to ease the training of networks that are
                substantially deeper than those used previously. We explicitly
                reformulate the layers as learning residual functions with
                reference to the layer inputs, instead of learning unreferenced
                functions. We provide comprehensive empirical evidence showing
                that these residual networks are easier to optimize, and can
                gain accuracy from considerably increased depth. On the
                ImageNet dataset we evaluate residual nets with a depth of up
                to 152 layers---8x deeper than VGG nets but still having lower
                complexity. An ensemble of these residual nets achieves 3.57%
                error on the ImageNet test set. This result won the 1st place
                on the ILSVRC 2015 classification task. We also present
                analysis on CIFAR-10 with 100 and 1000 layers.

                The depth of representations is of central importance for many
                visual recognition tasks. Solely due to our extremely deep
                representations, we obtain a 28% relative improvement on the
                COCO object detection dataset. Deep residual nets are
                foundations of our submissions to ILSVRC & COCO 2015
                competitions, where we also won the 1st places on the tasks of
                ImageNet detection, ImageNet localization, COCO detection, and
                COCO segmentation.
        },
        comments = {
                Presents a way of training deeper networks via residual
                functions. Won ILSVRC 2015 CLS. Key insight is that deeper
                networks can be trained by trying to represent residual
                function H(x) - x rather than representing H(x) itself.
        }
}

@article{DBLP:journals/corr/SimonyanZ14a,
        author    = {Karen Simonyan and Andrew Zisserman},
        title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
        journal   = {CoRR},
        volume    = {abs/1409.1556},
        year      = {2014},
        url       = {http://arxiv.org/abs/1409.1556},
        timestamp = {Wed, 01 Oct 2014 15:00:05 +0200},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SimonyanZ14a},
        bibsource = {dblp computer science bibliography, http://dblp.org}
}

@incollection{NIPS2014_5423,
        title = {Generative Adversarial Nets},
        author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and
                  Xu, Bing and Warde-Farley, David and Ozair, Sherjil and
                  Courville, Aaron and Bengio, Yoshua},
        booktitle = {Advances in Neural Information Processing Systems 27},
        editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence
                and K. Q. Weinberger},
        pages = {2672--2680},
        year = {2014},
        publisher = {Curran Associates, Inc.},
        url = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
        abstract = {
                We propose a new framework for estimating generative models via
                an adversarial process, in which we simultaneously train two
                models: a generative model G that captures the data
                distribution, and a discriminative model D that estimates the
                probability that a sample came from the training data rather
                than G. The training procedure for G is to maximize the
                probability of D making a mistake. This framework corresponds
                to a minimax two-player game. In the space of arbitrary
                functions G and D, a unique solution exists, with G recovering
                the training data distribution and D equal to 1/2 everywhere.
                In the case where G and D are defined by multilayer
                perceptrons, the entire system can be trained with
                backpropagation. There is no need for any Markov chains or
                unrolled approximate inference networks during either training
                or generation of samples. Experiments demonstrate the potential
                of the framework through qualitative and quantitative
                evaluation of the generated samples.
        },
        comments = {
                Original paper presenting GANs. Presents GAN algorithm, and
                formally proves that the optimal discriminator guesses randomly
                between the data distribution and the generated distribution.
                Shows qualitative generative results on CIFAR-10 using MLPs and
                ConvNets. Suggests issues with GANs such as no exact model of
                the probability distribution p_g produced by the generator.
        }
}

@article{deepSpeechReviewSPM2012,
        author={Geoffrey E. Hinton and Li Deng and Dong Yu and George E. Dahl
                and Abdel{-}rahman Mohamed and Navdeep Jaitly and Andrew Senior
                and Vincent Vanhoucke and Patrick Nguyen and Tara N. Sainath
                and Brian Kingsbury},
        title     = {Deep Neural Networks for Acoustic Modeling in Speech Recognition:
                     The Shared Views of Four Research Groups},
        journal   = {IEEE Signal Process. Mag.},
        volume    = {29},
        number    = {6},
        year      = {2012},
        pages     = {82-97},
        abstract = {
        }
}

@inproceedings{icml2010_NairH10,
        Publisher = {Omnipress},
        Title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
        Url = {http://www.icml2010.org/papers/432.pdf},
        Booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
        Author = {Vinod Nair and Geoffrey E. Hinton},
        Editor = {Johannes Fürnkranz and Thorsten Joachims},
        Year = {2010},
        Pages = {807-814},
        abstract = {
              Restricted Boltzmann machines were devel- oped using binary
              stochastic hidden units.  These can be generalized by
              replacing each binary unit by an infinite number of
              copies that all have the same weights but have pro-
              gressively more negative biases. The learning and
              inference rules for these “Stepped Sig- moid Units” are
              unchanged. They can be ap- proximated efficiently by
              noisy, rectified lin- ear units. Compared with binary
              units, these units learn features that are better for
              object recognition on the NORB dataset and face
              verification on the Labeled Faces in the Wild dataset.
              Unlike binary units, rectified linear units preserve
              information about relative in- tensities as information
              travels through mul- tiple layers of feature detectors.
        }
   }

@article{DBLP:journals/corr/IsolaZZE16,
        author    = {Phillip Isola and
                Jun{-}Yan Zhu and
                        Tinghui Zhou and
                        Alexei A. Efros},
        title     = {Image-to-Image Translation with Conditional Adversarial Networks},
        journal   = {CoRR},
        volume    = {abs/1611.07004},
        year      = {2016},
        url       = {http://arxiv.org/abs/1611.07004},
        timestamp = {Thu, 01 Dec 2016 19:32:08 +0100},
        biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/IsolaZZE16},
        bibsource = {dblp computer science bibliography, http://dblp.org},
        abstract = {
                We investigate conditional adversarial networks as a
                general-purpose solution to image-to-image translation
                problems. These networks not only learn the mapping
                from input image to output image, but also learn a loss
                function to train this mapping. This makes it possible
                to apply the same generic approach to problems that
                traditionally would require very different loss
                formulations. We demonstrate that this approach is
                effective at synthesizing photos from label maps,
                reconstructing objects from edge maps, and colorizing images,
                among other tasks. As a community, we no longer hand-engineer
                our mapping functions, and this work suggests we can
                achieve reasonable results without hand-engineering our
                loss functions either.
        },
        comments = {
                Extends the idea of GANs from (Goodfellow et al., 2014) to
                cGANs (conditional GANs) and applies cGANs to various
                image-to-image translation tasks, such as generating images
                from segmentation masks or edges.

                Shows that for generative structured graphical tasks, it is
                possible to learn a loss for the generative network in the form
                of the discriminator loss. The discriminator convolves over and
                tries to classify whether NxN regions of the output are samples
                from the ground truth distribution or from the generated
                distribution. Optimal N is found to be 70px.

                It is left as an open question to figure out how to generate
                stochastic outputs so as to mimic the true distribution of
                outputs.
        }
}

@article{maas_rectified_nonlinearities,
        author = {
                Andrew L. Maas and Awni Y. Hannun and Andrew Y. Ng
        },
        title = {Rectifier Nonlinearities Improve Neural Network Acoustic
                 Models},
        journal = {ICML},
        year = {2013},
        url = {http://ai.stanford.edu/~amaas/papers/relu_hybrid_icml2013_final.pdf},
        abstract = {
                Deep neural network acoustic models produce
                substantial gains in large vocabulary
                continuous speech recognition systems.
                Emerging work with rectified linear (ReL)
                hidden units demonstrates additional gains
                in final system performance relative to more
                commonly used sigmoidal nonlinearities. In
                this work, we explore the use of deep rectifier
                networks as acoustic models for the 300 hour
                Switchboard conversational speech recognition
                task. Using simple training procedures
                without pretraining, networks with rectifier
                nonlinearities produce 2% absolute reductions
                in word error rates over their sigmoidal
                counterparts. We analyze hidden layer representations
                to quantify differences in how ReL
                units encode inputs as compared to sigmoidal
                units. Finally, we evaluate a variant of the
                ReL unit with a gradient more amenable to
                optimization in an attempt to further improve
                deep rectifier networks.
        },
        comments = {
                Introduces Leaky ReLUs to deal with vanishing gradient problem
                (leaky ReLUs have non-zero gradient over their domain). Leaky
                ReLUs are found to perform similarly to ReLUs, and to converge
                slightly faster.
        }
}
